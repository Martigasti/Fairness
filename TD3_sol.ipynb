{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 66330,
     "status": "ok",
     "timestamp": 1707202682814,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "R1WJwi7C9Ng5",
    "outputId": "ec9c5093-9e95-40c2-d729-00d2bc4c01ad"
   },
   "source": [
    "Here are the dependencies, the last two are new\n",
    "\n",
    "`pip install numpy==1.25 fairlearn==0.9.0 plotly==5.24.1 nbformat==5.10.4 aif360['inFairness']==0.6.1 ipykernel==6.29.5 BlackBoxAuditing==0.1.54 cvxpy==1.6.0 `\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OepcePtF1hIS"
   },
   "source": [
    "!!! Attention sur Colab!!!, après avoir executé la cellule ci-dessus, il faudra redémarrer la session (onglet \"Execution\") afin de charger l'environnement installé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRe6S30b9Ng7"
   },
   "source": [
    "# TD 3: Mitigation des biais avec des méthodes de pré-processing et de post-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c9ITNS89NhA"
   },
   "source": [
    "## 1.Manipulate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707202697233,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "88mMZIic9NhB",
    "outputId": "f0be967d-0531-4dd0-8d13-39accc70509e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", append=True, category=UserWarning)\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "MEPSDataset19_data = MEPSDataset19()\n",
    "(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test) = (\n",
    "    MEPSDataset19().split([0.5, 0.8], shuffle=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 20083,
     "status": "ok",
     "timestamp": 1707202719711,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "LYbdfIPs9NhE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7915, 4749, 3166)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_orig_panel19_train.instance_weights), len(\n",
    "    dataset_orig_panel19_val.instance_weights\n",
    "), len(dataset_orig_panel19_test.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21854.981705, 18169.604822, 17191.832515, ...,  3896.116219,\n",
       "        4883.851005,  6630.588948])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_weights = MEPSDataset19_data.instance_weights\n",
    "instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taille du dataset 15830, poids total du dataset 141367240.546316.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Taille du dataset {len(instance_weights)}, poids total du dataset {instance_weights.sum()}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion en dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(MepsDataset):\n",
    "    data = MepsDataset.convert_to_dataframe()\n",
    "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
    "    df = data[0]\n",
    "    df[\"WEIGHT\"] = data[1][\"instance_weights\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_df(MEPSDataset19_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous réalisons maintenant l'opération inverse (qui sera indispensable pour le projet). Créer un objet de la classe StandardDataset de AIF360 à partir du dataframe. \n",
    "\n",
    "Pour le projet cela vous permettre d'utiliser les méthode déjà implémentées dans AIF360 sur votre jeu de données.\n",
    "\n",
    "Ici cela n'a aucun intéret car le dataframe vien d'un StandardDataset, nous vous fournissons le code. Mais cela vaut le coup de le lire attentivement et de poser des questions si besoin.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from aif360.datasets import StandardDataset\n",
    "import pandas as pd\n",
    "\n",
    "# Get categorical column from one hot encoding (specitic to MEPSdataset)\n",
    "# Here we create a dictionnary that links each categorical column name\n",
    "# to the list of corresponding one hot encoded columns\n",
    "categorical_columns_dic = {}\n",
    "for col in df.columns:\n",
    "    col_split = col.split(\"=\")\n",
    "    if len(col_split) > 1:\n",
    "        cat_col = col_split[0]\n",
    "        if not (cat_col in categorical_columns_dic.keys()):\n",
    "            categorical_columns_dic[cat_col] = []\n",
    "        categorical_columns_dic[cat_col].append(col)\n",
    "categorical_features = categorical_columns_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15830, 140)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15830, 43)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we recreate the categorical column value from the one hot encoded\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "def categorical_transform(df, onehotencoded, cat_col):\n",
    "    if len(onehotencoded) > 1:\n",
    "        return df[onehotencoded].apply(\n",
    "            lambda x: onehotencoded[np.argmax(x)][len(cat_col) + 1 :], axis=1\n",
    "        )\n",
    "    else:\n",
    "        return df[onehotencoded]\n",
    "\n",
    "\n",
    "# Reverse the categorical one hot encoded\n",
    "for cat_col, onehotencoded in categorical_columns_dic.items():\n",
    "    df[cat_col] = categorical_transform(df, onehotencoded, cat_col)\n",
    "    df.drop(columns=onehotencoded, inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDataset = StandardDataset(\n",
    "    df=df,\n",
    "    label_name=\"UTILIZATION\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"RACE\"],\n",
    "    privileged_classes=[[1]],\n",
    "    instance_weights_name=\"WEIGHT\",\n",
    "    categorical_features=categorical_features,\n",
    "    features_to_keep=[],\n",
    "    features_to_drop=[],\n",
    "    na_values=[\"?\", \"Unknown/Invalid\"],\n",
    "    custom_preprocessing=None,\n",
    "    metadata=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49826823461176517 0.21507139363038463\n",
      "0.49826823461176517 0.21507139363038463\n"
     ]
    }
   ],
   "source": [
    "# We check the dataset has the same metrics :D\n",
    "# Attention étonnanement le positive label 'favorable_classes' est par défaut 1 (cela est un peu bizarre pour ce dataset)\n",
    "print(\n",
    "    BinaryLabelDatasetMetric(\n",
    "        MEPSDataset19_data,\n",
    "        unprivileged_groups=[{\"RACE\": 0}],\n",
    "        privileged_groups=[{\"RACE\": 1}],\n",
    "    ).disparate_impact(),\n",
    "    BinaryLabelDatasetMetric(\n",
    "        MEPSDataset19_data,\n",
    "        unprivileged_groups=[{\"RACE\": 0}],\n",
    "        privileged_groups=[{\"RACE\": 1}],\n",
    "    ).base_rate(),\n",
    ")\n",
    "print(\n",
    "    BinaryLabelDatasetMetric(\n",
    "        MyDataset, unprivileged_groups=[{\"RACE\": 0}], privileged_groups=[{\"RACE\": 1}]\n",
    "    ).disparate_impact(),\n",
    "    BinaryLabelDatasetMetric(\n",
    "        MyDataset, unprivileged_groups=[{\"RACE\": 0}], privileged_groups=[{\"RACE\": 1}]\n",
    "    ).base_rate(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4982682346117653, 0.21507139363038463)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aif360.sklearn.metrics import disparate_impact_ratio, base_rate\n",
    "\n",
    "dir = disparate_impact_ratio(\n",
    "    y_true=df.UTILIZATION, prot_attr=df.RACE, pos_label=1, sample_weight=df.WEIGHT\n",
    ")\n",
    "br = base_rate(y_true=df.UTILIZATION, pos_label=1, sample_weight=df.WEIGHT)\n",
    "dir, br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question1: Create a function that print the fairness metrics of a dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1707202720196,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "Ah6tnyOt9NhF",
    "outputId": "bb7a9c32-7695-45dd-92e4-82916d96e3be"
   },
   "outputs": [],
   "source": [
    "from aif360.sklearn.metrics import *\n",
    "\n",
    "\n",
    "def get_group_metrics(\n",
    "    y_true,\n",
    "    y_pred=None,\n",
    "    prot_attr=None,\n",
    "    priv_group=1,\n",
    "    pos_label=1,\n",
    "    sample_weight=None,\n",
    "):\n",
    "    group_metrics = {}\n",
    "    group_metrics[\"base_rate\"] = base_rate(\n",
    "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    if not y_pred is None:\n",
    "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "    return group_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.21507139363038463,\n",
       " 'statistical_parity_difference': -0.13507447726478136,\n",
       " 'disparate_impact_ratio': 0.4982682346117653}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_metrics = get_group_metrics(\n",
    "        y_true= df.UTILIZATION,\n",
    "        y_pred= None,\n",
    "        prot_attr= df.RACE,\n",
    "        pos_label= 1,\n",
    "        sample_weight= df.WEIGHT,\n",
    ")\n",
    "group_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3Zbw-U4mTKf"
   },
   "source": [
    "## 2. Appliquer les méthodes de pré-processing disponibles dans AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RACE', [{'RACE': 0.0}], [{'RACE': 1.0}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "unprivileged_groups = [\n",
    "    {sens_attr: v}\n",
    "    for v in dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]\n",
    "]\n",
    "privileged_groups = [\n",
    "    {sens_attr: v}\n",
    "    for v in dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]\n",
    "]\n",
    "sens_attr, unprivileged_groups, privileged_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Quesiton: Apprendre une regression logistique qui prédit l'UTILIZATION\n",
    "\n",
    "Attention nous avons enlever le preprocessing sur le dataframe, il faut cette fois utiliser l'API d'AIF360\n",
    "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.StructuredDataset.html\n",
    "\n",
    "pour retrouver les features (X), les labels (y) et les poids de chaque instance du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469502635753938"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X_train = dataset_orig_panel19_train.features\n",
    "y_train = dataset_orig_panel19_train.labels[:,0]\n",
    "X_val = dataset_orig_panel19_val.features\n",
    "y_val = dataset_orig_panel19_val.labels[:,0]\n",
    "\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "model = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **{\"logisticregression__sample_weight\": dataset_orig_panel19_train.instance_weights}\n",
    ")\n",
    "\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "model.score(X_val, y_val, sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8469502635753938, 0.705306798187123)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, preds, sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, preds, sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Question: Calcul des métriques de fairness\n",
    "\n",
    "Calculer les métriques du dataset de validation seul.\n",
    "\n",
    "Calculer les métriques basées sur les prédictions et la vérité du dataset de validation.\n",
    "\n",
    "En comparaison calculer les métriques basées sur des prédictions aléatoires et la vérité du dataset de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.12134966576028675,\n",
       " 'disparate_impact_ratio': 0.5260990512554462}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics on validation dataset\n",
    "get_group_metrics(\n",
    "        y_true=y_val,\n",
    "        y_pred=None,\n",
    "        prot_attr=dataset_orig_panel19_val.protected_attributes[:, sens_ind],\n",
    "        pos_label=1,\n",
    "        sample_weight=dataset_orig_panel19_val.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.11419180291702838,\n",
       " 'disparate_impact_ratio': 0.37940849083495765,\n",
       " 'equal_opportunity_difference': -0.1712968207977449,\n",
       " 'average_odds_difference': -0.10771665651734363,\n",
       " 'conditional_demographic_disparity': -0.04463003128116544,\n",
       " 'smoothed_edf': 0.969141552940342,\n",
       " 'df_bias_amplification': 0.3268758988759921}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics based on predictions and truth on validation dataset\n",
    "get_group_metrics(\n",
    "        y_true=y_val,\n",
    "        y_pred=preds,\n",
    "        prot_attr=dataset_orig_panel19_val.protected_attributes[:, sens_ind],\n",
    "        pos_label=1,\n",
    "        sample_weight=dataset_orig_panel19_val.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.0035456211554041883,\n",
       " 'disparate_impact_ratio': 0.9928829221410262,\n",
       " 'equal_opportunity_difference': -0.09712682476440238,\n",
       " 'average_odds_difference': -0.0395212623132353,\n",
       " 'conditional_demographic_disparity': -0.0006591341968137991,\n",
       " 'smoothed_edf': 0.007142524585142529,\n",
       " 'df_bias_amplification': -0.6351231294792073}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics based on random predictions and truth on validation dataset\n",
    "\n",
    "pred_random = np.array([int(r*2) for r in np.random.random(size=len(y_val)).tolist()])\n",
    "pred_random.max(), pred_random.min()\n",
    "get_group_metrics(\n",
    "        y_true=y_val,\n",
    "        y_pred=pred_random,\n",
    "        prot_attr=dataset_orig_panel19_val.protected_attributes[:, sens_ind],\n",
    "        pos_label=1,\n",
    "        sample_weight=dataset_orig_panel19_val.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Repondération\n",
    "#### 2.2.1. Question : Trouver dans l'API quels objets/fonctions sont à utiliser pour faire de repondération et les appliquer sur le dataset d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import *\n",
    "\n",
    "RW = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW.fit(dataset_orig_panel19_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_panel19_train)\n",
    "dataset_transf_val = RW.transform(dataset_orig_panel19_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Question: Apprendre une regression logistique sur les données pondérées et calculer les métriques de fairness sur l'échantillon de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu en cours le Reweighting ne modifie que la pondération du dataset, les features et label restent inchangés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8677616340282165, 0.8468268453442269)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rw = make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "model_rw = model_rw.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **{\"logisticregression__sample_weight\": dataset_transf_train.instance_weights}\n",
    ")\n",
    "\n",
    "preds_rw = model_rw.predict(X_val)\n",
    "\n",
    "model_rw.score(X_val, y_val), model_rw.score(X_val, y_val, sample_weight=dataset_transf_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84889536077611, 0.7044360411962385)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, preds_rw, sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, preds_rw, sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.2095619112874149,\n",
       " 'statistical_parity_difference': 0.0006922227730098707,\n",
       " 'disparate_impact_ratio': 1.0051842240054536,\n",
       " 'equal_opportunity_difference': -0.025632212931009424,\n",
       " 'average_odds_difference': -0.012963255560900694,\n",
       " 'conditional_demographic_disparity': 0.00028098957787494683,\n",
       " 'smoothed_edf': 0.005170883017437067,\n",
       " 'df_bias_amplification': -0.06936987668262229}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics on prediction with RW on validation dataset\n",
    "get_group_metrics(\n",
    "    y_true=y_val,\n",
    "    y_pred=preds_rw,\n",
    "    prot_attr=dataset_orig_panel19_val.protected_attributes[:, sens_ind],\n",
    "    pos_label=1,\n",
    "    sample_weight=dataset_transf_val.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Disparate Impact Remover\n",
    "#### 2.3.1. Question : Trouver dans l'API quels objets/fonctions sont à utiliser pour faire une approache de disparate impact remover et les appliquer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = DisparateImpactRemover(repair_level=1., sensitive_attribute='RACE')\n",
    "train_dir = DIR.fit_transform(dataset_orig_panel19_train)\n",
    "val_dir = DIR.fit_transform(dataset_orig_panel19_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights features                                    \\\n",
       "                                         protected attribute                 \n",
       "                                     AGE                RACE  PCS42  MCS42   \n",
       "instance names                                                               \n",
       "13074               4854.422747     13.0                 0.0  -1.00  -1.00   \n",
       "598                 6491.605615     56.0                 0.0  32.00  63.40   \n",
       "12539               5746.605598     47.0                 0.0  55.09  56.74   \n",
       "2337               11967.358980     85.0                 1.0  35.24  44.77   \n",
       "1487               17276.935353     25.0                 1.0  56.15  57.16   \n",
       "...                         ...      ...                 ...    ...    ...   \n",
       "605                 3825.982645      2.0                 1.0  -1.00  -1.00   \n",
       "5317                1031.365179     29.0                 0.0  -1.00  -1.00   \n",
       "15974               7555.375410     41.0                 0.0  51.01  53.67   \n",
       "9068                4114.271125     36.0                 0.0  52.40  62.66   \n",
       "12297               1389.189624     25.0                 0.0  56.15  51.41   \n",
       "\n",
       "                                                            ...          \\\n",
       "                                                            ...           \n",
       "               K6SUM42 REGION=1 REGION=2 REGION=3 REGION=4  ... EMPST=4   \n",
       "instance names                                              ...           \n",
       "13074             -1.0      1.0      0.0      0.0      0.0  ...     0.0   \n",
       "598                0.0      0.0      1.0      0.0      0.0  ...     0.0   \n",
       "12539              0.0      0.0      0.0      1.0      0.0  ...     0.0   \n",
       "2337               4.0      1.0      0.0      0.0      0.0  ...     1.0   \n",
       "1487               1.0      0.0      1.0      0.0      0.0  ...     0.0   \n",
       "...                ...      ...      ...      ...      ...  ...     ...   \n",
       "605               -1.0      0.0      1.0      0.0      0.0  ...     0.0   \n",
       "5317              -1.0      0.0      0.0      1.0      0.0  ...     1.0   \n",
       "15974              0.0      1.0      0.0      0.0      0.0  ...     0.0   \n",
       "9068               0.0      0.0      0.0      1.0      0.0  ...     0.0   \n",
       "12297              0.0      0.0      0.0      1.0      0.0  ...     1.0   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                                \n",
       "               POVCAT=1 POVCAT=2 POVCAT=3 POVCAT=4 POVCAT=5 INSCOV=1 INSCOV=2   \n",
       "instance names                                                                  \n",
       "13074               0.0      0.0      0.0      1.0      0.0      0.0      1.0   \n",
       "598                 0.0      0.0      0.0      0.0      1.0      1.0      0.0   \n",
       "12539               0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "2337                0.0      0.0      0.0      1.0      0.0      1.0      0.0   \n",
       "1487                0.0      0.0      0.0      1.0      0.0      1.0      0.0   \n",
       "...                 ...      ...      ...      ...      ...      ...      ...   \n",
       "605                 1.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "5317                1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "15974               0.0      0.0      0.0      0.0      1.0      0.0      1.0   \n",
       "9068                0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "12297               1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "                        labels  \n",
       "                                \n",
       "               INSCOV=3         \n",
       "instance names                  \n",
       "13074               0.0    0.0  \n",
       "598                 0.0    0.0  \n",
       "12539               1.0    0.0  \n",
       "2337                0.0    1.0  \n",
       "1487                0.0    0.0  \n",
       "...                 ...    ...  \n",
       "605                 0.0    0.0  \n",
       "5317                1.0    0.0  \n",
       "15974               0.0    0.0  \n",
       "9068                1.0    0.0  \n",
       "12297               1.0    0.0  \n",
       "\n",
       "[7915 rows x 140 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig_panel19_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights features                                    \\\n",
       "                                         protected attribute                 \n",
       "                                     AGE                RACE  PCS42  MCS42   \n",
       "instance names                                                               \n",
       "13074               4854.422747     13.0                 0.0  -1.00  -1.00   \n",
       "598                 6491.605615     56.0                 0.0  29.10  63.23   \n",
       "12539               5746.605598     47.0                 0.0  55.09  56.74   \n",
       "2337               11967.358980     85.0                 1.0  35.24  44.42   \n",
       "1487               17276.935353     25.0                 1.0  56.01  57.16   \n",
       "...                         ...      ...                 ...    ...    ...   \n",
       "605                 3825.982645      2.0                 1.0  -1.00  -1.00   \n",
       "5317                1031.365179     29.0                 0.0  -1.00  -1.00   \n",
       "15974               7555.375410     41.0                 0.0  50.83  53.67   \n",
       "9068                4114.271125     36.0                 0.0  52.33  62.49   \n",
       "12297               1389.189624     25.0                 0.0  56.15  51.41   \n",
       "\n",
       "                                                            ...          \\\n",
       "                                                            ...           \n",
       "               K6SUM42 REGION=1 REGION=2 REGION=3 REGION=4  ... EMPST=4   \n",
       "instance names                                              ...           \n",
       "13074             -1.0      1.0      0.0      0.0      0.0  ...     0.0   \n",
       "598                0.0      0.0      1.0      0.0      0.0  ...     0.0   \n",
       "12539              0.0      0.0      0.0      1.0      0.0  ...     0.0   \n",
       "2337               4.0      1.0      0.0      0.0      0.0  ...     1.0   \n",
       "1487               1.0      0.0      1.0      0.0      0.0  ...     0.0   \n",
       "...                ...      ...      ...      ...      ...  ...     ...   \n",
       "605               -1.0      0.0      1.0      0.0      0.0  ...     0.0   \n",
       "5317              -1.0      0.0      0.0      1.0      0.0  ...     1.0   \n",
       "15974              0.0      1.0      0.0      0.0      0.0  ...     0.0   \n",
       "9068               0.0      0.0      0.0      1.0      0.0  ...     0.0   \n",
       "12297              0.0      0.0      0.0      1.0      0.0  ...     1.0   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                                \n",
       "               POVCAT=1 POVCAT=2 POVCAT=3 POVCAT=4 POVCAT=5 INSCOV=1 INSCOV=2   \n",
       "instance names                                                                  \n",
       "13074               0.0      0.0      0.0      1.0      0.0      0.0      1.0   \n",
       "598                 0.0      0.0      0.0      0.0      1.0      1.0      0.0   \n",
       "12539               0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "2337                0.0      0.0      0.0      1.0      0.0      1.0      0.0   \n",
       "1487                0.0      0.0      0.0      1.0      0.0      1.0      0.0   \n",
       "...                 ...      ...      ...      ...      ...      ...      ...   \n",
       "605                 1.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "5317                1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "15974               0.0      0.0      0.0      0.0      1.0      0.0      1.0   \n",
       "9068                0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "12297               1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "                        labels  \n",
       "                                \n",
       "               INSCOV=3         \n",
       "instance names                  \n",
       "13074               0.0    0.0  \n",
       "598                 0.0    0.0  \n",
       "12539               1.0    0.0  \n",
       "2337                0.0    1.0  \n",
       "1487                0.0    0.0  \n",
       "...                 ...    ...  \n",
       "605                 0.0    0.0  \n",
       "5317                1.0    0.0  \n",
       "15974               0.0    0.0  \n",
       "9068                1.0    0.0  \n",
       "12297               1.0    0.0  \n",
       "\n",
       "[7915 rows x 140 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Question: Apprendre une regression logistique sur les données transformées en retirant l'attribut sensible et calculer les métriques de fairness sur l'échantillon de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8514288533074994"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protected=\"RACE\"\n",
    "index = dataset_orig_panel19_train.feature_names.index(protected)\n",
    "model_dir = make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "model_dir = model_dir.fit(\n",
    "    np.delete(train_dir.features, index, axis=1),\n",
    "    train_dir.labels[:,0],\n",
    "    **{\"logisticregression__sample_weight\": train_dir.instance_weights}\n",
    ")\n",
    "\n",
    "preds_dir = model_dir.predict(np.delete(val_dir.features, index, axis=1))\n",
    "\n",
    "model_dir.score(np.delete(val_dir.features, index, axis=1), val_dir.labels[:,0], sample_weight=val_dir.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8514288533074994, 0.7129236915393814)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, preds_dir, sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, preds_dir, sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.0931466144269939,\n",
       " 'disparate_impact_ratio': 0.4719865662720144,\n",
       " 'equal_opportunity_difference': -0.11607039635390687,\n",
       " 'average_odds_difference': -0.07166894763436302,\n",
       " 'conditional_demographic_disparity': -0.03620763647608569,\n",
       " 'smoothed_edf': 0.7508045374105108,\n",
       " 'df_bias_amplification': 0.10853888334616091}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_group_metrics(\n",
    "    y_true=val_dir.labels[:,0],\n",
    "    y_pred=preds_dir,\n",
    "    prot_attr=val_dir.protected_attributes[:, sens_ind],\n",
    "    pos_label=1,\n",
    "    sample_weight=val_dir.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Question: Apprentissage de représentation latente fair\n",
    "\n",
    "Apprendre le pre-processing et evaluer son impact avec les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 1.4659595773313123, L_x: 73.94598829174177,  L_y: 0.49051756409957825,  L_z: 0.004719642606286328\n",
      "step: 250, loss: 1.46595971088572, L_x: 73.94598833018088,  L_y: 0.49051756006723446,  L_z: 0.00471964535033354\n",
      "step: 500, loss: 1.4659595696651782, L_x: 73.94598828277832,  L_y: 0.49051756446983963,  L_z: 0.004719642447351108\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          695     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.46596D+00    |proj g|=  2.04111D-01\n",
      "step: 750, loss: 1.272585756019214, L_x: 73.89492042874119,  L_y: 0.46301402602024677,  L_z: 0.001412450514231106\n",
      "step: 1000, loss: 1.2725855361078842, L_x: 73.89492042960904,  L_y: 0.46301402461390384,  L_z: 0.0014124461439578018\n",
      "step: 1250, loss: 1.2725853566771945, L_x: 73.8949204625469,  L_y: 0.4630140320109748,  L_z: 0.0014124424008150117\n",
      "\n",
      "At iterate    1    f=  1.27259D+00    |proj g|=  1.71041D-01\n",
      "step: 1500, loss: 1.7371397847844399, L_x: 73.58618197198047,  L_y: 0.5362537999427979,  L_z: 0.00930048330243675\n",
      "step: 1750, loss: 1.73713960998383, L_x: 73.58618194157862,  L_y: 0.5362537999199181,  L_z: 0.009300479812962517\n",
      "step: 2000, loss: 1.737139518281439, L_x: 73.58618192122029,  L_y: 0.536253798041274,  L_z: 0.009300478020559246\n",
      "step: 2250, loss: 1.2887354493045469, L_x: 73.86707183177775,  L_y: 0.46335468401011853,  L_z: 0.001734200939533015\n",
      "step: 2500, loss: 1.2887355327003687, L_x: 73.86707181480438,  L_y: 0.4633546858166213,  L_z: 0.0017342025747140721\n",
      "step: 2750, loss: 1.2887354215444096, L_x: 73.86707178804093,  L_y: 0.46335468947962793,  L_z: 0.001734200283687448\n",
      "step: 3000, loss: 1.2593242238910025, L_x: 73.8864002579252,  L_y: 0.4628746112324229,  L_z: 0.0011517122015865522\n",
      "step: 3250, loss: 1.259324144776091, L_x: 73.88640027526264,  L_y: 0.462874615704163,  L_z: 0.0011517105263860294\n",
      "\n",
      "At iterate    2    f=  1.25932D+00    |proj g|=  2.41885D-01\n",
      "step: 3500, loss: 1.2752589839956814, L_x: 73.87244388270176,  L_y: 0.4637685987166921,  L_z: 0.001455318929039434\n",
      "step: 3750, loss: 1.2752587425705015, L_x: 73.87244383783843,  L_y: 0.4637686006499383,  L_z: 0.0014553140708435774\n",
      "step: 4000, loss: 1.2752590111077646, L_x: 73.87244389990124,  L_y: 0.4637686115965147,  L_z: 0.0014553192102447488\n",
      "step: 4250, loss: 1.2541130494275083, L_x: 73.883305005169,  L_y: 0.46305108251904803,  L_z: 0.0010445783371354044\n",
      "step: 4500, loss: 1.2541129002781135, L_x: 73.8833050389207,  L_y: 0.4630510858582858,  L_z: 0.0010445752806124142\n",
      "step: 4750, loss: 1.254112981001091, L_x: 73.88330505320681,  L_y: 0.46305108771435344,  L_z: 0.0010445768550933876\n",
      "\n",
      "At iterate    3    f=  1.25411D+00    |proj g|=  1.54750D-01\n",
      "step: 5000, loss: 1.2400089206129086, L_x: 73.89090353370841,  L_y: 0.46361864837421496,  L_z: 0.0007496247380321897\n",
      "step: 5250, loss: 1.2400088967864025, L_x: 73.89090353246338,  L_y: 0.4636186491915256,  L_z: 0.0007496242454048619\n",
      "step: 5500, loss: 1.2400089275240702, L_x: 73.89090353511915,  L_y: 0.463618646640042,  L_z: 0.000749624910656732\n",
      "step: 5750, loss: 1.2582291106096362, L_x: 73.91206245289705,  L_y: 0.46811090855281207,  L_z: 0.0010199515505570744\n",
      "step: 6000, loss: 1.2582292345918378, L_x: 73.91206246021162,  L_y: 0.4681109172084723,  L_z: 0.0010199538556249833\n",
      "step: 6250, loss: 1.2582289748727034, L_x: 73.91206243769149,  L_y: 0.46811090487815693,  L_z: 0.0010199489123526306\n",
      "step: 6500, loss: 1.224599796861468, L_x: 73.90012618959571,  L_y: 0.46482303888065857,  L_z: 0.0004155099216970437\n",
      "step: 6750, loss: 1.2245997016306802, L_x: 73.90012619569795,  L_y: 0.46482303060950386,  L_z: 0.00041550818128393565\n",
      "\n",
      "At iterate    4    f=  1.22460D+00    |proj g|=  1.84904D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  695      4     10      5     0     1   1.849D-01   1.225D+00\n",
      "  F =   1.2245998271127039     \n",
      "\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT        \n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "TR = LFR(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    k=5,\n",
    "    Ax=0.01,\n",
    "    Ay=1.0,\n",
    "    Az=50.0,\n",
    "    print_interval=250,\n",
    "    verbose=1,\n",
    "    seed=None,\n",
    ")\n",
    "TR = TR.fit(dataset_orig_panel19_train, maxiter=5000, maxfun=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data and align features\n",
    "dataset_transf_train = TR.transform(dataset_orig_panel19_train)\n",
    "dataset_transf_val = TR.transform(dataset_orig_panel19_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922054620722778"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lfr = make_pipeline(StandardScaler(), LogisticRegression(solver='liblinear', random_state=42))\n",
    "\n",
    "model_lfr = model_lfr.fit(\n",
    "    dataset_transf_train.features,\n",
    "    y_train,\n",
    "    **{\"logisticregression__sample_weight\": dataset_transf_train.instance_weights}\n",
    ")\n",
    "\n",
    "preds_lfr = model_lfr.predict(dataset_transf_val.features)\n",
    "\n",
    "model_lfr.score(dataset_transf_val.features, y_val, sample_weight=dataset_transf_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7922054620722778, 0.4995661116350048)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, preds_lfr, sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, preds_lfr, sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.0011533968392891188,\n",
       " 'disparate_impact_ratio': 0.0,\n",
       " 'equal_opportunity_difference': 0.0,\n",
       " 'average_odds_difference': -0.0007752004925231093,\n",
       " 'conditional_demographic_disparity': -0.0779575236497689,\n",
       " 'smoothed_edf': 9.900830448204257,\n",
       " 'df_bias_amplification': 9.258564794139907}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_group_metrics(\n",
    "            y_true=y_val,\n",
    "            y_pred=preds_lfr,\n",
    "            prot_attr=dataset_transf_val.protected_attributes[:, sens_ind],\n",
    "            pos_label=1,\n",
    "            sample_weight=dataset_transf_val.instance_weights,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Question: Use the post-processing Reject Option Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing.reject_option_classification import (\n",
    "    RejectOptionClassification,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Reuse the first Logistic Regression learn to find the best threshold that maximises its balanced accuracy on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best classification threshold of the validation dataset\n",
    "df_val_pred = dataset_orig_panel19_val.copy(deepcopy=True)\n",
    "df_val_pred.scores = model.predict_proba(dataset_orig_panel19_val.features)[:,1].reshape(-1,1)\n",
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = df_val_pred.scores > class_thresh\n",
    "    df_val_pred.labels[fav_inds] = df_val_pred.favorable_label\n",
    "    df_val_pred.labels[~fav_inds] = df_val_pred.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_panel19_val,\n",
    "                                             df_val_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' best indice 23, corresponding balanced accuracy 0.7623408122393942, and threshold 0.23767676767676768'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\" best indice {best_ind}, corresponding balanced accuracy {ba_arr[best_ind]}, and threshold {best_class_thresh}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Use the RejectOptionClassification  on the validation dataset with the logistic regression predictions. To improve the fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"Statistical parity difference\"\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "\n",
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "\n",
    "ROC = ROC.fit(dataset_orig_panel19_val, df_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.2080\n",
      "Optimal ROC margin = 0.0764\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.04249645116073564,\n",
       " 'disparate_impact_ratio': 0.8618525286313132,\n",
       " 'equal_opportunity_difference': 0.05410668027317256,\n",
       " 'average_odds_difference': 0.03430762918665692,\n",
       " 'conditional_demographic_disparity': -0.009582586906338744,\n",
       " 'smoothed_edf': 0.14867107665762447,\n",
       " 'df_bias_amplification': -0.4935945774067254}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc_val_pred = ROC.predict(df_val_pred)\n",
    "get_group_metrics(\n",
    "    y_true=y_val,\n",
    "    y_pred=df_roc_val_pred.labels[:,0],\n",
    "    prot_attr=df_val_pred.protected_attributes[:, sens_ind],\n",
    "    pos_label=1,\n",
    "    sample_weight=df_val_pred.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7940235015673595, 0.7607647568837854)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, df_roc_val_pred.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, df_roc_val_pred.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Do the same while starting from the Logistic Regression learned on the Reweighted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best classification threshold of the validation dataset\n",
    "df_val_pred_rw = dataset_orig_panel19_val.copy(deepcopy=True)\n",
    "df_val_pred_rw.scores = model_rw.predict_proba(dataset_orig_panel19_val.features)[:,1].reshape(-1,1)\n",
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = df_val_pred_rw.scores > class_thresh\n",
    "    df_val_pred_rw.labels[fav_inds] = df_val_pred_rw.favorable_label\n",
    "    df_val_pred_rw.labels[~fav_inds] = df_val_pred_rw.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_panel19_val,\n",
    "                                             df_val_pred_rw, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' best indice 20, corresponding balanced accuracy 0.7634407716783915, and threshold 0.207979797979798'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\" best indice {best_ind}, corresponding balanced accuracy {ba_arr[best_ind]}, and threshold {best_class_thresh}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_rw = ROC.fit(dataset_orig_panel19_val, df_val_pred_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal classification threshold (with fairness constraints) = 0.2179\n",
      "Optimal ROC margin = 0.0044\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC_rw.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC_rw.ROC_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.04490734784958361,\n",
       " 'disparate_impact_ratio': 0.8561548632842189,\n",
       " 'equal_opportunity_difference': 0.0589910626589043,\n",
       " 'average_odds_difference': 0.03476425217100709,\n",
       " 'conditional_demographic_disparity': -0.010053205876755662,\n",
       " 'smoothed_edf': 0.1553039773326257,\n",
       " 'df_bias_amplification': -0.4869616767317242}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc_val_pred_rw = ROC.predict(df_val_pred_rw)\n",
    "get_group_metrics(\n",
    "    y_true=y_val,\n",
    "    y_pred=df_roc_val_pred_rw.labels[:,0],\n",
    "    prot_attr=df_val_pred_rw.protected_attributes[:, sens_ind],\n",
    "    pos_label=1,\n",
    "    sample_weight=df_val_pred_rw.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7919141161157263, 0.7607666558386222)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, df_roc_val_pred_rw.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, df_roc_val_pred_rw.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Use the Calibrated Equalised Odds  on the validation dataset with the logistic regression predictions. To improve the fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "# cost constraint of fnr will optimize generalized false negative rates, that of\n",
    "# fpr will optimize generalized false positive rates, and weighted will optimize\n",
    "# a weighted combination of both\n",
    "cost_constraint = \"fnr\" # \"fnr\", \"fpr\", \"weighted\"\n",
    "cpp = CalibratedEqOddsPostprocessing(privileged_groups = privileged_groups,\n",
    "                                     unprivileged_groups = unprivileged_groups,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=42)\n",
    "cpp = cpp.fit(dataset_orig_panel19_val, df_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.0008382875124766653,\n",
       " 'disparate_impact_ratio': 0.9881348544833901,\n",
       " 'equal_opportunity_difference': 0.14192622345508196,\n",
       " 'average_odds_difference': 0.07117364819110404,\n",
       " 'conditional_demographic_disparity': -0.0005959688147473498,\n",
       " 'smoothed_edf': 0.011935979500472982,\n",
       " 'df_bias_amplification': -0.6303296745638769}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ceqodds_val_pred = cpp.predict(df_val_pred)\n",
    "get_group_metrics(\n",
    "    y_true=y_val,\n",
    "    y_pred=df_ceqodds_val_pred.labels[:,0],\n",
    "    prot_attr=df_val_pred.protected_attributes[:, sens_ind],\n",
    "    pos_label=1,\n",
    "    sample_weight=df_val_pred.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8188781744393867, 0.602265005680144)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, df_ceqodds_val_pred.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, df_ceqodds_val_pred.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_rw = cpp.fit(dataset_orig_panel19_val, df_val_pred_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_rate': 0.20710648338464316,\n",
       " 'statistical_parity_difference': -0.054124769845432505,\n",
       " 'disparate_impact_ratio': 0.6518716969592314,\n",
       " 'equal_opportunity_difference': -0.025632212931009035,\n",
       " 'average_odds_difference': -0.012963255560900666,\n",
       " 'conditional_demographic_disparity': -0.02172567428554692,\n",
       " 'smoothed_edf': 0.4279073794370918,\n",
       " 'df_bias_amplification': -0.2143582746272581}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ceqodds_val_pred_rw = cpp_rw.predict(df_val_pred_rw)\n",
    "get_group_metrics(\n",
    "    y_true=y_val,\n",
    "    y_pred=df_ceqodds_val_pred_rw.labels[:,0],\n",
    "    prot_attr=df_val_pred_rw.protected_attributes[:, sens_ind],\n",
    "    pos_label=1,\n",
    "    sample_weight=df_val_pred_rw.instance_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84889536077611, 0.7044360411962385)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, df_ceqodds_val_pred_rw.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights), balanced_accuracy_score(y_val, df_ceqodds_val_pred_rw.labels[:,0], sample_weight=dataset_orig_panel19_val.instance_weights)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1reWieE41k1RU9_T08Chmufh9WOwBoIKZ",
     "timestamp": 1706013971768
    },
    {
     "file_id": "1fWzH-WkCZ9xcagC-8OY71_b_aNcXfdpM",
     "timestamp": 1705973751107
    }
   ]
  },
  "kernelspec": {
   "display_name": "td3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
